# Portfolio
---
## Dashboard - Looker Studio Project
### Data: Data Kependudukan Desa Pakisan

[View in Looker Studio](https://lookerstudio.google.com/reporting/3ceeb544-e9bc-4cbd-992a-d4845337dbd3)

<center><img src="images/pakisan.jpg"/></center>

### Data: COVID-19 Week 5 Global Dataset

[View in Looker Studio](https://lookerstudio.google.com/reporting/4ff8e5bd-cf9c-4a5c-8073-5335a290a777)

<center><img src="images/covid.jpg"/></center>

---

## SQL Project

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/himmafh/himmafh.github.io/blob/master/projects/handson.sql)

<div style="text-align: justify">Structured Query Language (SQL) is a standardized programming language that is used to manage relational databases and perform various operations on the dataset. In this project, the tools and the dataset that used are PostgreSQL and DVD Rental Dataset. By using PostgreSQL, there are some cases that must be solved with SQL query.</div>
1. Identify the top 10 customers and their email so we can reward them.<br>
2. Identify the bottom 10 customers and their emails.<br>
3. What are the most profitable movie genres (ratings)?<br>
4. How many rented movies were returned late, early, and on time?<br>
5. What is the customer base in the countries where we have a presence?<br>
6. Which country is the most profitable for the business?<br>
7. What is the average rental rate per movie genre (rating)?.<br>

<center><img src="images/postgresql.png"/></center>
<center><img src="images/postgresql2.png"/></center>

---

## Data Analytics with Python 

### Regression and Cluster Modeling
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1_Ap7mEC85gahSHvCYB5TN2hrRYXM293c?usp=sharing)

**Regression**<br>
<div style="text-align: justify">Regression is a statistical method that attempts to determine the strength and character of the relationship between dependent variable (usually denoted by Y) and a series of other variables (known as independent variables). Using House Prices - Advanced Regression Techniques Dataset, regression modeling is carried out with the following steps:</div>
1. Exploratory Data Analysis.<br>
2. Split the dataset into two parts, train and test data.<br>
3. Create a predictive model with linear regression using train data.<br>
4. Evaluate the predictive model that are made using R-Squared, Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE).</div>

<center><img src="images/reg.png"/></center>
<br>

**Cluster using K-Means CLustering**<br>
<div style="text-align: justify">K-Means Clustering is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. Using Mall Customers Dataset, clustering is carried out with the following steps:</div>
1. Exploratory Data Analysis.<br>
2. Determining the number of clusters with Elbow method and Silhouette method.<br>
3. Perform clustering.<br>
4. Evaluate the cluster that are made using silhouette coefficient, calinski-harabasz index, dan davies-bouldin index.</div>

<center><img src="images/clust.png"/></center>
<br>
  
### Exploratory Data Analysis
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1RngW7Uxgglqp60wcejG_omgVOJgjKlwN?usp=sharing)

<div style="text-align: justify">Exploratory Data Analysis is the process of describing the data by means of statistical analysis and visualization techniques for deeper analytics in data analytics. Using Telco Customer Churn Dataset, Exploratory Data Analysis is well done with the following steps:</div>
1. Data understanding, including data cleansing and data manipulation.<br>
2. Statistical summary, showing statistical values from dataset.<br>
3. Univariate analysis for numerical variables by pointing out boxplot, distribution plot, and countplot.<br>
4. Bivariate analysis for numerical variables by pointing out boxplot and countplot.<br>
5. Multivariate analysis for numerical variables by pointing out correlation heatmap and category plot.</div>

<center><img src="images/eda.png"/></center>
<br>

### Statistics with Python
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1nhttps:/colab.research.google.com/drive/1n7UjVWjxw7b1T_N9SpfNlh8QjhIErpEg?usp=sharing7UjVWjxw7b1T_N9SpfNlh8QjhIErpEg?usp=sharing)

<div style="text-align: justify">Statistics in data analytics helps make meaningful conclusion from raw and unstructured data. The conclusion that are made is used to helping businesses make future predictions on the basis of past trend. Using Diabetes dataset, statistical values (such as mean, median, mode, etc) and visualization of the dataset will be perfomed to facilitate decision-making.</div>

<center><img src="images/stat.png"/></center>
<center><img src="images/stat2.png"/></center>
<br>

### Data Visualization
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1Os0KYkOvLmxMH8Yf-ZWmD65vLsPudsMe?usp=sharing)

<div style="text-align: justify">Data visualization is the graphical representation of the data using visual elements like charts, graph, and maps. In this project, there will be visualized as barplot, distribution plot, boxplot, scatterplot, and pie chart using Seaborn and Matplotlib libraries. The data used is Titanic Dataset form Kaggle.</div>

<center><img src="images/vis.png"/></center>
<br>

### Data Manipulation with Pandas 
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1-lluAadg3aqU-V5h9pTuNIT1LXHkxIaM?usp=sharing)

<div style="text-align: justify">Data manipulation is the process of organizing data to make it more understandable. Data manipulation usually using Pandas library for join, merge, concat, and append the dataset. Before performing data visualization, data cleansing is first carried out on the dataset.</div>

<center><img src="images/manip.png"/></center>
<center><img src="images/manip2.png"/></center>
<br>

### Data Cleansing
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1ZvPLX4Ix3K4uT5skQo7OImXc37BBsyXJ?usp=sharing)

<div style="text-align: justify">Data cleansing is an essential process for preparing raw data for machine learning (ML) and business inteligence (BI) applications. Data cleansing is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. In this project, the data used is Telco Customer Churn Dataset from Kaggle.</div>

<div style="text-align: justify"><br>
The steps that were taken in data cleansing included: <br>
1. Missing value checking and handling, using fill method with median value.<br>
2. Categorical data encoding, using Label Encoding and Frequently Encoding.<br>
3. Anomalies and Outliers Handling. In this dataset, no anomalies or outliers were found.</div>

<center><img src="images/cleansing.png"/></center>
<br>

---
## Machine Learning Visualizations (Data: Monthly Visitors Museum)
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1blfZST840LWSWchQj-R0OesyELE3XfgY?usp=sharing)

<div style="text-align: justify">Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to imitate the way that humans learn, gradually improving its accuracy. With the help of data visualization, we can see how the data looks like and what kind of correlation is held by the attributes of data. It is the fastest way to see if the features correspond to the output. </div>

<center><img src="images/ml.png"/></center>
<br>

---
## Model Selection for Loan Classification with Home Credit Default Risk Dataset
[![Run in Google Colab](https://img.shields.io/badge/Colab-Run_in_Google_Colab-blue?logo=Google&logoColor=FDBA18)](https://colab.research.google.com/drive/1xQTibIinWJTk9M0gZqxKiTSzEK22-eyO?usp=sharing)

<div style="text-align: justify"> Home Credit is a non-bank financial institution focused on providing loans to individuals who may have limited or no credit history. The goal of this project is to determine the appropriate model for accurately and efficiently classifying loans, ensuring high accuracy in credit risk assessment. </div>

<center><img src="images/classification.png"/></center>
<br>

---
##  GUI Python application for calculating Value at Risk (VaR) for bonds

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/himmafh/himmafh.github.io/blob/master/projects/varobligasi.py)

<div style="text-align: justify"> Value at Risk (VaR) is a statistical measure that considers the historical volatility of risk factors and the correlations among these risk factors. The parametric approach calculates VaR based on parametric calculations such as the volatility of asset returns and the correlation between assets in the portfolio. One method to calculate VaR for bonds is the variance-covariance method, which assumes that the returns or percentage changes in prices of financial instruments follow a normal distribution.</div>

<br>
<center><img src="images/gui.png"/></center>
<br>

---
##  R Programming for forecasting future stock prices using ARIMA-IGARCH and forming a stock portfolio using Mean-Semivariance 

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/himmafh/himmafh.github.io/blob/master/projects/syntax.R)

<div style="text-align: justify"> The most popular investment instrument in the capital market are stocks. Investors not only have the potential for return but also the potential for risk of loss. The formation of a stock portfolio is an alternative to minimize risk. The objective of this study is to the volatility of stock returns using the ARIMA-IGARCH approach and form an optimal stock portfolio that minimizes risk using the Mean-Semivariance. 

<br>
<center><img src="images/forecast.png"/></center>
<center><img src="images/bobot.png"/></center>
<br>
